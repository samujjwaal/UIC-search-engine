{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T03:12:54.136867Z",
     "start_time": "2020-05-19T03:12:35.152097Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dependency libraries\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T03:13:33.549291Z",
     "start_time": "2020-05-19T03:13:33.534285Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of webpages indexed\n",
    "N = 6001\n",
    "\n",
    "# extracting english stop words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Initializing Porter Stemmer object\n",
    "st = PorterStemmer()\n",
    "\n",
    "# folder to store pickel files\n",
    "pickle_folder = \"../PickleFiles/\"\n",
    "os.makedirs(pickle_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T03:13:34.219286Z",
     "start_time": "2020-05-19T03:13:34.213284Z"
    }
   },
   "outputs": [],
   "source": [
    "webpages_idf = {}\n",
    "max_freq = {}\n",
    "webpages_tf_idf = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T03:13:36.434617Z",
     "start_time": "2020-05-19T03:13:35.350028Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(pickle_folder + '6000_inverted_index.pickle', 'rb') as f:\n",
    "    inverted_index = pickle.load(f)                   # rename\n",
    "\n",
    "with open(pickle_folder + '6000_webpages_tokens.pickle', 'rb') as f:\n",
    "    webpages_tokens = pickle.load(f)                   # rename\n",
    "\n",
    "with open(pickle_folder + '6000_pages_crawled.pickle', 'rb') as f:\n",
    "    urls = pickle.load(f)                   # rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:00.419055Z",
     "start_time": "2020-05-11T14:54:00.406048Z"
    }
   },
   "outputs": [],
   "source": [
    "# webpages_idf = {}\n",
    "\n",
    "# function for computing idf of each token in the collection of webpages\n",
    "\n",
    "def calc_idf(inverted_index):\n",
    "    # df = {}\n",
    "    idf = {}\n",
    "\n",
    "    for key in inverted_index.keys():\n",
    "        df = len(inverted_index[key].keys())\n",
    "        idf[key] = math.log2(N/df)\n",
    "    \n",
    "    return idf\n",
    "    \n",
    "# webpages_idf = calc_idf(inverted_index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:00.543266Z",
     "start_time": "2020-05-11T14:54:00.423060Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_freq = {}\n",
    "\n",
    "# for page in webpages_tokens:\n",
    "#     most_freq_token = mode(webpages_tokens[page])\n",
    "#     max_freq[page] = inverted_index[most_freq_token][page]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:00.684527Z",
     "start_time": "2020-05-11T14:54:00.548170Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_freq = {}\n",
    "\n",
    "# for page in webpages_tokens:\n",
    "#     max_freq[page] = Counter(webpages_tokens[page]).most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:00.777742Z",
     "start_time": "2020-05-11T14:54:00.688456Z"
    }
   },
   "outputs": [],
   "source": [
    "# webpages_tf_idf = {}\n",
    "\n",
    "# function to compute tf-idf of each token\n",
    "\n",
    "def calc_tfidf(inverted_index):\n",
    "    \n",
    "    # making a temporary copy of the inverted index\n",
    "    tf_idf = copy.deepcopy(inverted_index)\n",
    "    \n",
    "    for token in tf_idf:\n",
    "        for page in tf_idf[token]:\n",
    "            tf = tf_idf[token][page] / max_freq[page]\n",
    "            tf_idf[token][page] = tf * webpages_idf[token]\n",
    "    \n",
    "    return tf_idf\n",
    "\n",
    "# webpages_tf_idf = calc_tfidf(inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:00.885854Z",
     "start_time": "2020-05-11T14:54:00.781091Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_doc_len(doc, doc_tokens):\n",
    "    doc_len = 0\n",
    "    \n",
    "    for token in set(doc_tokens):\n",
    "        \n",
    "        doc_len += webpages_tf_idf[token][doc] ** 2\n",
    "    \n",
    "    doc_len = math.sqrt(doc_len)\n",
    "    \n",
    "    return doc_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:01.011314Z",
     "start_time": "2020-05-11T14:54:00.887798Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate doc lengths for each fetched webpage\n",
    "\n",
    "def doc_len_pages(list_of_tokens):\n",
    "    \n",
    "    doc_lens = {}\n",
    "    \n",
    "    for page in list_of_tokens:\n",
    "        \n",
    "#         print(page)\n",
    "        doc_lens[page] = calc_doc_len(page, list_of_tokens[page])\n",
    "        \n",
    "    return doc_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:01.136005Z",
     "start_time": "2020-05-11T14:54:01.014284Z"
    }
   },
   "outputs": [],
   "source": [
    "# doc_len_pages(webpages_tokens)\n",
    "# webpages_lens = doc_len_pages(webpages_tokens)\n",
    "# webpages_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:01.260402Z",
     "start_time": "2020-05-11T14:54:01.138825Z"
    }
   },
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# t = []\n",
    "# for token in inverted_index:\n",
    "# #     print(inverted_index[token]['0'])\n",
    "#     if c:= inverted_index[token].get('0'):\n",
    "# #         count += 1\n",
    "#         count += c \n",
    "#         t.append(token)\n",
    "\n",
    "# # count\n",
    "# # t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:01.542597Z",
     "start_time": "2020-05-11T14:54:01.262634Z"
    }
   },
   "outputs": [],
   "source": [
    "# set(t) == set(webpages_tokens['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:01.838792Z",
     "start_time": "2020-05-11T14:54:01.545463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute cosine similarity\n",
    "\n",
    "def calc_cos_sim_scores(query, doc_lens):\n",
    "    similarity_scores = {}\n",
    "    query_len = 0\n",
    "    query_weights = {}\n",
    "    \n",
    "    query_dict = Counter(query)\n",
    "    \n",
    "    \n",
    "    for token in query_dict.keys():\n",
    "        token_tf = query_dict[token] / query_dict.most_common(1)[0][1]\n",
    "        query_weights[token] = token_tf * webpages_idf.get(token,0)\n",
    "        query_len += query_weights[token] ** 2\n",
    "    \n",
    "    query_len = math.sqrt(query_len)\n",
    "#     print(query_len,query_weights)\n",
    "\n",
    "    \n",
    "    for token in query:\n",
    "        token_weight = query_weights.get(token)\n",
    "#         print(token_weight)\n",
    "        \n",
    "        if token_weight:\n",
    "#             print(token_weight)\n",
    "            for page in webpages_tf_idf[token].keys():\n",
    "                similarity_scores[page] = similarity_scores.get(page,0) + (webpages_tf_idf[token][page] * token_weight)\n",
    "#                 print(tf_idf[token][page], token_weight)\n",
    "    \n",
    "#     print(similarity_scores)\n",
    "    \n",
    "    for page in similarity_scores:\n",
    "        similarity_scores[page] = similarity_scores[page] / (doc_lens[page] * query_len)\n",
    "        \n",
    "#     print(similarity_scores)\n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:01.966157Z",
     "start_time": "2020-05-11T14:54:01.841847Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to tokenize query text\n",
    "\n",
    "def tokenize_query(query_text):\n",
    "    text = query_text.lower()\n",
    "    text = re.sub('[^a-z]+', ' ', text)\n",
    "    tokens = text.split()\n",
    "    clean_stem_tokens = [\n",
    "            st.stem(token) for token in tokens \n",
    "            if (token not in stop_words and st.stem(token) not in stop_words) and len(st.stem(token))>2\n",
    "        ]\n",
    "    return clean_stem_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:02.122426Z",
     "start_time": "2020-05-11T14:54:01.969155Z"
    }
   },
   "outputs": [],
   "source": [
    "# query_text = query.lower()\n",
    "# query_text = re.sub('[^a-z]+', ' ', query_text)\n",
    "# query_tokens = query_text.split()\n",
    "# clean_stem_query_tokens = [\n",
    "#         st.stem(token) for token in query_tokens \n",
    "#         if (token not in stop_words and st.stem(token) not in stop_words) and len(st.stem(token))>2\n",
    "#     ]\n",
    "# clean_stem_query_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:02.420919Z",
     "start_time": "2020-05-11T14:54:02.125468Z"
    }
   },
   "outputs": [],
   "source": [
    "# query_tokens = tokenize_query(query)\n",
    "# query_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:02.530523Z",
     "start_time": "2020-05-11T14:54:02.423330Z"
    }
   },
   "outputs": [],
   "source": [
    "# query_sim_pages = calc_cos_sim_scores(query_tokens, webpages_lens)\n",
    "# most_relevant_pages = sorted(query_sim_pages.items(), key= lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:02.654514Z",
     "start_time": "2020-05-11T14:54:02.533539Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_relevant_pages(count,webpages):\n",
    "    for i in range(count, count+10):\n",
    "#         print(webpages[i])\n",
    "        try:\n",
    "            url_no = int(webpages[i][0])\n",
    "            \n",
    "        except Exception as e: \n",
    "            print(\"\\nNo more results found !!\")\n",
    "            break\n",
    "            \n",
    "#         print(url_no)\n",
    "        if urls.get(url_no, None):\n",
    "            print(i+1,urls.get(url_no))\n",
    "    \n",
    "# show_relevant_pages(0,most_relevant_pages)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:08.220578Z",
     "start_time": "2020-05-11T14:54:02.657525Z"
    }
   },
   "outputs": [],
   "source": [
    "webpages_idf = calc_idf(inverted_index)\n",
    "\n",
    "for page in webpages_tokens:\n",
    "    max_freq[page] = Counter(webpages_tokens[page]).most_common(1)[0][1]\n",
    "    \n",
    "webpages_tf_idf = calc_tfidf(inverted_index)\n",
    "webpages_lens = doc_len_pages(webpages_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:18.519829Z",
     "start_time": "2020-05-11T14:54:08.220578Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     ---UIC Web Search Engine---\n",
      "\n",
      "Enter a search query: information retrieval\n",
      "\n",
      "\n",
      "1 https://cs.uic.edu/profiles/cornelia-caragea\n",
      "2 http://cs.uic.edu/profiles/cornelia-caragea\n",
      "3 https://engineering.uic.edu/letter-from-the-dean-spring-2020\n",
      "4 https://registrar.uic.edu/student_records/transcripts\n",
      "5 http://www.uic.edu/depts/oar/student_records/transcripts.html\n",
      "6 https://registrar.uic.edu/current_students/transcripts.html\n",
      "7 https://researchguides.uic.edu/dataplans/preservingdata\n",
      "8 https://transportation.uic.edu/abandoned-bicycle-removal\n",
      "9 http://csrc.uic.edu\n",
      "10 https://csrc.uic.edu\n",
      "\n",
      "Do you want to more web page results? n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\n                     ---UIC Web Search Engine---\\n')\n",
    "query = str(input(\"Enter a search query: \"))\n",
    "print('\\n')\n",
    "query_tokens = tokenize_query(query)\n",
    "\n",
    "query_sim_pages = calc_cos_sim_scores(query_tokens, webpages_lens)\n",
    "most_relevant_pages = sorted(query_sim_pages.items(), key= lambda x: x[1], reverse=True)\n",
    "\n",
    "yes = {'y','yes'}\n",
    "first_pass = True\n",
    "count = 0\n",
    "\n",
    "while first_pass or choice.lower() in yes:\n",
    "    first_pass = False\n",
    "    show_relevant_pages(count, most_relevant_pages)\n",
    "    choice = str(input(\"\\nDo you want to more web page results? \"))\n",
    "    count += 10"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
