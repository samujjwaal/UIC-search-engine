
<HTML>
<!-- <BODY BGCOLOR="#AAAAAA" TEXT="#000000" LINK="#9690CC"> -->

<BODY BGCOLOR="#FFFFFF">

<HEAD> 
<TITLE> CS 583 Spring 2019 </TITLE>
</HEAD>
<BODY>
<H2>
<center>
CS 583 - Spring 2019 (two sections)
</center>
</H2> 
<h1>
<center>
Data Mining and Text Mining
</H1>
</center>

<H3> Course Objective </h3>
<p>This course has three objectives. First, to provide students with a sound basis in data mining tasks and techniques. Second, to ensure that students are able to read, and critically evaluate data mining research papers. Third, to ensue that students are able to implement and to use some of the important data mining and text mining algorithms. 

<h3> Think and Ask! </h3>
<p> If you have questions about any topic or assignment, DO ASK me or 
even your classmates for help, I am here to make the course 
undersdood. DO NOT delay your questions. There is no such thing as a 
stupid question. The only obstacle to learning is laziness. </p>

<table> 
<tr>
<td width="30%" valign=top> 
<h3> General Information </h3> 
<UL>
<LI> Instructor: Bing Liu 
<ul> 
   <li> Email: <a href="http://www.cs.uic.edu/~liub"> Bing Liu</a>
   <li> Tel: (312) 355 1318
   <li> Office: North end, 3rd floor, library
</ul>
<li> Teaching Assistants: 
  <ul>
     <li> Section 1: Sahisnu Mazumder, sahisnumazumder@gmail.com 
     <li> Section 2: Shuai Wang, swang207@uic.edu; 
     <li> Office hours: by appointment
  </ul>
</ul>
</td>

<td width="30%" valign=top> 
<h3> Section 1 </h3>
<ul>
<LI> Course Call Number: 25479
<LI> Lecture time slot: 
     <ul>
       <li> 12:30-1:45pm  Tuesday & Thursday
     </ul>
<LI> Lecture hall: LC A7
<li> Office hours: 2:00pm-3:00pm, Tuesday & Thursday (or by appointment)
</ul>
</td>

<td width="30%" valign=top> 
<h3> Section 2 </h3>
<ul>
<LI> Course Call Number: 39840
<LI> Lecture time slot: 
     <ul>
       <li> 3:30-4:45pm  Tuesday & Thursday
     </ul>
<LI> Lecture hall: LC A4
<li> Office hours: 2:00pm-3:00pm, Tuesday & Thursday (or by appointment)
</ul>
</td></tr></table>


<H3>Grading</H3>
</ul>
<li> Quizzes: 10% (2 or more)
<ul>
<li> Date and time: TBA
</ul>
<li> Midterm: 30% (2 midterms)
<ul>
<li> Date and time: TBA
</ul>
<li> Final Exam: 40%
<ul>
<li> Date and time: TBA
</ul>
<li> Projects: Done in groups (2 students per group)
<ul>
<li> Project 1: TBA (10%) (algorithm implementation)
<ul>
<li> Demo date: TBA
</ul>
<li> Project 2: TBA (10%) (research)
<ul>
<li> Demo date: TBA
<li> Report due: TBA
</ul>
</ul>
</ul>
<P>
<H3>Prerequisites</H3>
<UL>
<li> Knowledge of probability and algorithms 
<li> Any program language for projects
</ul>
<p>
<H3> Teaching materials </H3> 
<ul>
<li> Required Textbook:
<ul>
<li><a href="http://www.cs.uic.edu/~liub/WebMiningBook.html"><b>Web data 
Mining</b> - Exploring Hyperlinks, Contents and Usage Data</a>, By Bing Liu, Second Edition, Springer, July 2011, ISBN 978-3-642-19459-7 
</ul>
<li> References
  <ul>
  <li> Data mining: Concepts and Techniques, by Jiawei Han and Micheline Kamber, Morgan Kaufmann Publishers, ISBN 1-55860-489-8. 
  <li> Introduction to Data Mining, by Pang-Ning Tan, Michael Steinbach, and Vipin Kumar, Pearson/Addison Wesley, ISBN 0-321-32136-7. 
  <li> Data Miining. by Charu Aggarwal, Springer, 2015. ISBN 978-3-319-14142-8
  <li> Machine Learning, by Tom M. Mitchell, McGraw-Hill, ISBN 0-07-042807-7
  <li> Principles of Data Mining, by David Hand, Heikki Mannila, Padhraic Smyth, The MIT Press, ISBN 0-262-08290-X. 
  <li> <a href="https://www.cs.uic.edu/~liub/lifelong-machine-learning-draft.pdf">Lifelong machine learning</a>, by Zhiyuan Chen and Bing Liu, Morgan & Claypool Publishers, November 2016. 
  <li> <a href="https://www.amazon.com/Sentiment-Analysis-Opinions-Sentiments-Emotions-ebook/dp/B00Y37YXIG">Sentiment Analysis: Mining Opinions, Sentiments, and Emotions</a>, by Bing Liu, Cambridge University Press, 2015. 
  </ul>
<li> Data mining resource site: <a href="http://www.kdnuggets.com/index.html"> KDnuggets Directory </a>
</ul>
<H3> Topics (subject to change; the reading list follows each chapter title)</H3> 

<ol> 
<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-spring-19/CS583-introduction.ppt"> Introduction </a>

<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-fall-05/CS583-data-prep.ppt"> Data pre-processing  </a>
<ul>
<li> Data cleaning
<li> Data transformation
<li> Data reduction
<li> Discretization
</ul>
<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-spring-19/CS583-association-sequential-patterns.ppt"> Association rules and sequential patterns</a> (Sections 2.1 - 2.7)
     <ul> 
     <li> Basic concepts
     <li> Apriori Algorithm
     <li> Mining association rules with multiple minimum supports 
     <li> Mining class association rules
     <li> Sequetial pattern mining
     <li> Summary
     </ul>
<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-fall-18/CS583-supervised-learning.ppt"> Supervised learning (Classification)</a> (Chapter 3)
     <ul> 
     <li> Basic concepts
     <li> Decision trees
     <li> Classifier evaluation
     <li> Rule induction
     <li> Classification based on association rules
     <li> Naive-Bayesian learning
     <li> Naive-Bayesian learning for text classification
     <li> Support vector machines
     <li> K-nearest neighbor
     <li> Bagging and boosting
     <li> Summary
     </ul>
<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-fall-05/CS583-unsupervised-learning.ppt"> Unsupervised learning (Clustering)</a> (Chapter 4)
     <ul> 
     <li> Basic concepts
     <li> K-means algorithm
     <li> Representation of clusters
     <li> Hierarchical clustering
     <li> Distance functions
     <li> Data standardization
     <li> Handling mixed attributes
     <li> Which clustering algorithm to use?
     <li> Cluster evaluation
     <li> Discovering holes and data regions
     <li> Summary
     </ul>
<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-spring-07/CS583-info-retrieval.ppt"> Information retrieval and Web search</a> (Sections 6.1 - 6.6, and 6.8)
     <ul>
     <li> Basic text processing and representation
     <li> Cosine similarity
     <li> Relevance feedback and Rocchio algorithm
     </ul> 

<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-fall-16/CS583-semi-supervised-learning.ppt"> Semi-supervised learning </a> (Sections 5.1.1, 5.1.2, 5.2.1 - 5.2.4) 
     <ul>
     <li> LU learning: Learning from labeled and unlabeled examples
     <ul> 
        <li> Learning from labeled and unlabeled examples using EM
        <li> Learning from labeled and unlabeled examples using co-training
     </ul>
     <li> PU learning: Learning from positive and unlabeled examples
     </ul>
<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-spring-19/CS583-link-analysis.ppt">Social network analysis</a> (Sections 7.1 - 7.4)
     <ul>
     <li> Centrality and prestige
     <li> Citation analysis: co-citation and bibliographic coupling
     <li> The PageRank algoithm (of Google)
     <li> The HITS algorithm: authorities and hubs
     <li> Mining communities on the Web
     </ul>
<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-fall-11/CS583-opinion-mining.ppt"> Sentiment analysis and opinion mining </a> (Sections 11.1 - 11.6; check out my <a href="http://www.cs.uic.edu/~liub">two books</a>)

<ul>
<li> Opinion mining problem
<li> Document-level Sentiment classification
<li> Sentence-level subjectivity and sentiment classification
<li> Aspect-level sentiment analysis
<li> Mining comparative opinions 
<li> Opinion lexicon generation
</ul>
<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-spring-11/CS583-recommender-systems.ppt"> Recommender systems and collaborative filtering</a> (Section 12.4)

     <ul>
<li>Content-based recommendation
<li>Collaborative filtering based recommendation
<ul>
<li> K-nearest neighbor
<li> Association rules
<li> Matrix factorization
</ul>
</ul>
<li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-fall-11/CS583-structured-data-extraction.ppt"> Web data extraction</a> (Sections 9.1 and 9.2)
<ul>
<li> Wrapper induction 
<li> Automated extraction
</ul>
<li> <a href="https://www.cs.uic.edu/~liub/lifelong-machine-learning-draft.pdf">Lifelong machine learning</a> (chapter 1; sections 2.1, 2.2, 3.1, 3.2, 3.4, 4.4, 4.5; chapter 5)
     <ul>
     <li> What is lifelong machine learning?
     <li> Lifelong supervised learning
     <li> Lifelong unsupervised learning
     <li> Lifelong semi-supervised learning
     </ul>
<!-- <li> <a href="http://www.cs.uic.edu/~liub/teach/cs583-fall-11/CS583-information-integration.ppt"> Information integration</a> (Section 10.8) -->
</ul> 

</ol>
<H3> Projects - graded  (you will demo your programs to me)</H3>
<ul>
<li> Each group consists of 2 students, and will work on two assignments
<ol>
<li> Algorithm implementation: TBA
<li> Research: TBA 
</ol>
</ul>
</ol>
<br>
<H3> Rules and Policies </H3> 
<uL>
<li> <b>Statute of limitations</b>: No grading questions or complaints, no matter how justified, will be listened to one week after the item in question has been returned. 
<li> <b>Cheating</b>: Cheating will not be tolerated. All work you submitted must be entirely your own. Any suspicious similarities between students' work (this includes, exams and program) will be recorded and brought to the attention of the Dean. The MINIMUM penalty for any student found cheating will be to receive a 0 for the item in question, and dropping your final course grade one letter. The MAXIMUM penalty will be expulsion from the University. 
<li> <b>MOSS</b>: Sharing code with your classmates is not acceptable!!! All programs will be screened using the Moss (Measure of Software Similarity.) system. 
<li> <b>Late assignments</b>: Late assignments will not, in general, be accepted. They will never be accepted if the student has not made special arrangements with me at least one day before the assignment is due. If a late assignment is accepted it is subject to a reduction in score as a late penalty. 

</ul>
<br>
Back to <a href="http://www.cs.uic.edu/~liub">Home Page</a>
<ADDRESS>
By Bing Liu, Jan 15, 2018
</ADDRESS>
</BODY>
</HTML>
